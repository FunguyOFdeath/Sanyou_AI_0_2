# core/recognizer.py
from __future__ import annotations

import os
import gc
import queue
import threading
from pathlib import Path
from typing import Callable, Optional, Dict, Tuple

# üö´ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º CUDA –∏ –≥–∞—Å–∏–º –∫–æ–Ω—Ñ–ª–∏–∫—Ç OpenMP
os.environ.setdefault("CUDA_VISIBLE_DEVICES", "-1")
os.environ.setdefault("KMP_DUPLICATE_LIB_OK", "TRUE")

import numpy as np
import torch
import whisper

from .config import ConfigManager
from .log_utils import LogFile
from .audio import list_input_devices, open_input_stream, apply_gain, denoise_wiener
from .vad import EnergyVAD


# –æ–≥—Ä–∞–Ω–∏—á–∏–º –ø–æ—Ç–æ–∫–∏ BLAS
try:
    torch.set_num_threads(max(1, min(os.cpu_count() or 2, 4)))
except Exception:
    pass


class WhisperRecognizer:
    """
    –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ—Ñ–ª–∞–π–Ω-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ (Whisper) –¥–ª—è {ru,en,zh}.
    –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
      ‚Ä¢ –º–æ–¥–µ–ª—å –≥—Ä—É–∑–∏—Ç—Å—è –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ (—Å—Ç–∞—Ç—É—Å 'loading');
      ‚Ä¢ –æ—á–µ—Ä–µ–¥–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã (–±–µ–∑ —É—Ç–µ—á–∫–∏ RAM);
      ‚Ä¢ VAD/NR/—É—Å–∏–ª–µ–Ω–∏–µ ‚Äî –Ω–∞ –ª–µ—Ç—É;
      ‚Ä¢ —Ä–µ–∂–∏–º—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç/–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç/–∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–π;
      ‚Ä¢ –∞–∫–∫—É—Ä–∞—Ç–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–æ–≤.
    GUI –∏—Å–ø–æ–ª—å–∑—É–µ—Ç:
      - start(), pause(), resume(), stop()
      - apply_new_settings(...)
      - detect_language_from_audio(audio, sr)
      - —Å–≤–æ–π—Å—Ç–≤–∞: is_running, is_paused, log_path
      - —Å–æ–±—ã—Ç–∏—è: on_text(str), on_info(str), on_status(str)
    """

    def __init__(
        self,
        on_text: Callable[[str], None],
        on_info: Optional[Callable[[str], None]] = None,
        on_status: Optional[Callable[[str], None]] = None,
        config: Optional[ConfigManager] = None,
        frame_ms: int = 200,
    ) -> None:
        self.on_text = on_text
        self.on_info = on_info or (lambda s: None)
        self.on_status = on_status or (lambda s: None)

        self.cfg = config or ConfigManager()
        self.sr = int(self.cfg.sample_rate)
        self.frame = int(self.sr * frame_ms / 1000.0)

        base = Path(__file__).resolve().parents[1]
        logs_dir = base / "logs"
        self.log = LogFile(logs_dir)
        self.log_path = self.log.path

        self._emit_info(f"[INFO] PyTorch {torch.__version__} | CUDA: {torch.cuda.is_available()}")
        self._emit_info(f"[INFO] Model: {self.cfg.model_name} | SR: {self.sr} | Device: CPU")

        # –º–æ–¥–µ–ª—å lazy: –∑–∞–≥—Ä—É–∑–∏–º –≤ —Ñ–æ–Ω–µ –Ω–∞ start()
        self.model: Optional[whisper.Whisper] = None
        self._loading = False

        # —Ä–∞–±–æ—á–∏–µ –æ–±—ä–µ–∫—Ç—ã
        self._audio_q: "queue.Queue[np.ndarray]" = queue.Queue(maxsize=12)
        self._stream_thread: Optional[threading.Thread] = None
        self._proc_thread: Optional[threading.Thread] = None
        self._stop_evt = threading.Event()

        # vad
        self.vad = EnergyVAD(sr=self.sr)

        # —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.is_running = False
        self.is_paused = False

        # —è–∑—ã–∫–∏
        self._allowed = {"ru", "en", "zh"}
        self._last_lang: Optional[str] = None

    # ---------- –ø—É–±–ª–∏—á–Ω—ã–π API ----------
    def start(self) -> None:
        if self.is_running:
            return
        self.is_running = True
        self.is_paused = False
        self._stop_evt.clear()

        if self.model is None and not self._loading:
            self._loading = True
            self._emit_status("loading")
            t = threading.Thread(target=self._load_model_bg, daemon=True)
            t.start()

        # –ø–æ—Ç–æ–∫ —á—Ç–µ–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        self._stream_thread = threading.Thread(target=self._mic_loop, daemon=True)
        self._stream_thread.start()

        # –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self._proc_thread = threading.Thread(target=self._process_loop, daemon=True)
        self._proc_thread.start()

    def pause(self) -> None:
        if not self.is_running:
            return
        self.is_paused = True
        self._emit_status("paused")
        self._emit_info("‚è∏ –ü–∞—É–∑–∞")

    def resume(self) -> None:
        if not self.is_running:
            return
        self.is_paused = False
        if self.model is not None:
            self._emit_status("running")
        else:
            self._emit_status("loading")
        self._emit_info("‚ñ∂ –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–æ")

    def stop(self) -> None:
        if not self.is_running:
            return
        self.is_running = False
        self.is_paused = False
        self._stop_evt.set()
        # –æ—Å–≤–æ–±–æ–¥–∏–º –æ—á–µ—Ä–µ–¥—å
        try:
            while not self._audio_q.empty():
                self._audio_q.get_nowait()
        except Exception:
            pass
        # –¥–æ–∂–¥—ë–º—Å—è
        for th in (self._stream_thread, self._proc_thread):
            try:
                if th and th.is_alive():
                    th.join(timeout=1.5)
            except Exception:
                pass
        self._emit_status("stopped")
        self._emit_info("üõë –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")

    def apply_new_settings(
        self,
        device_index: Optional[int],
        gain_db: float,
        noise_reduction: bool,
        lang_mode: Optional[str] = None,
        chosen_lang: Optional[str] = None,
        model_name: Optional[str] = None,   # ‚Üê –¥–æ–±–∞–≤–ª–µ–Ω–æ
    ) -> None:
        # –º–∏–∫—Ä–æ—Ñ–æ–Ω / –æ–±—Ä–∞–±–æ—Ç–∫–∞
        self.cfg.device_index = device_index
        self.cfg.gain_db = gain_db
        self.cfg.noise_reduction = noise_reduction
        # —è–∑—ã–∫–∏
        if lang_mode is not None:
            self.cfg.lang_mode = lang_mode
        if chosen_lang is not None:
            self.cfg.chosen_lang = chosen_lang
        # –º–æ–¥–µ–ª—å
        if model_name and model_name != self.cfg.model_name:
            old = self.cfg.model_name
            self.cfg.model_name = model_name
            # –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å –∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏–º –Ω–∞ —Å—Ç–∞—Ä—Ç–µ
            try:
                self.model = None
                gc.collect()
            except Exception:
                pass
            self._emit_info(f"[INFO] –ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞: {old} ‚Üí {self.cfg.model_name}. –ë—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ.")

    # –¥–ª—è —Ç–µ—Å—Ç–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
    def detect_language_from_audio(self, audio: np.ndarray, sr: int) -> Tuple[str, float]:
        x = self._resample_if_needed(audio, sr)
        x = whisper.pad_or_trim(x.astype(np.float32))
        if self.cfg.noise_reduction:
            x = denoise_wiener(x)
        mel = whisper.log_mel_spectrogram(x)
        if self.model is None:
            # –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (–º–∞–ª—É—é) —Ç–æ–ª—å–∫–æ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —è–∑—ã–∫–∞
            tmp_model = whisper.load_model("tiny", device="cpu")
            _, probs = tmp_model.detect_language(mel)
        else:
            _, probs = self.model.detect_language(mel)
        filt = {k: v for k, v in probs.items() if k in self._allowed}
        if not filt:
            return ("en", 0.0)
        lang = max(filt, key=filt.get)
        return (lang, float(filt[lang]))

    # ---------- –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ ----------
    def _load_model_bg(self):
        try:
            self._emit_info(f"[INFO] Loading Whisper model '{self.cfg.model_name}'...")
            self.model = whisper.load_model(self.cfg.model_name, device="cpu")
            if not self.is_paused and self.is_running:
                self._emit_status("running")
            self._emit_info("[INFO] Model ready.")
        except Exception as e:
            self._emit_info(f"[ERROR] Model load failed: {e}")
        finally:
            self._loading = False

    def _mic_loop(self):
        """–ß—Ç–µ–Ω–∏–µ –∞—É–¥–∏–æ ‚Üí –æ—á–µ—Ä–µ–¥—å."""
        def _cb(indata, frames, time_info, status):
            if self._stop_evt.is_set():
                return
            if status:
                self._emit_info(f"[AUDIO] {status}")
            if not self.is_running or self.is_paused:
                return
            x = indata.reshape(-1).astype(np.float32)
            x = apply_gain(x, self.cfg.gain_db)
            try:
                self._audio_q.put_nowait(x)
            except queue.Full:
                pass

        try:
            stream = open_input_stream(
                callback=_cb,
                samplerate=self.sr,
                device_index=self.cfg.device_index,
                blocksize=self.frame,
                channels=1,
            )
            with stream:
                while self.is_running and not self._stop_evt.is_set():
                    import time
                    time.sleep(0.05)
        except Exception as e:
            self._emit_info(f"[ERROR] Audio stream: {e}")
            self.stop()

    def _process_loop(self):
        self.vad.reset()
        while self.is_running and not self._stop_evt.is_set():
            try:
                x = self._audio_q.get(timeout=0.3)
            except queue.Empty:
                continue

            if self.is_paused:
                self.vad.reset()
                continue

            utt = self.vad.feed(x)
            if utt is None:
                continue

            if self.model is None:
                self._emit_info("‚Ä¶ (model loading)")
                continue

            y = whisper.pad_or_trim(utt.astype(np.float32))
            if self.cfg.noise_reduction:
                y = denoise_wiener(y)

            mode = self.cfg.lang_mode
            if mode == "exclusive":
                lang = self.cfg.chosen_lang if self.cfg.chosen_lang in self._allowed else "ru"
                text = self._asr(y, lang)
            elif mode == "priority":
                primary = self.cfg.chosen_lang if self.cfg.chosen_lang in self._allowed else "ru"
                text = self._asr(y, primary)
                if len(text.strip()) < 2:
                    lang = self._best_lang(y, exclude={primary})
                    text = self._asr(y, lang)
                else:
                    lang = primary
            else:
                lang = self._best_lang(y)
                if self._last_lang and lang != self._last_lang:
                    lang2 = self._best_lang(y, force=True)
                    lang = lang2
                self._last_lang = lang
                text = self._asr(y, lang)

            if text:
                line = f"[{lang.upper()}] {text.strip()}"
                self._emit_text(line)
                self.log.write(line)
                self._emit_info(line)

    # --- helpers ---
    def _best_lang(self, audio: np.ndarray, exclude: Optional[set] = None, force: bool = False) -> str:
        mel = whisper.log_mel_spectrogram(audio)
        _, probs = self.model.detect_language(mel)  # type: ignore[union-attr]
        filt: Dict[str, float] = {k: float(v) for k, v in probs.items() if k in self._allowed}
        if exclude:
            for k in list(filt.keys()):
                if k in exclude:
                    filt.pop(k, None)
        if not filt:
            return self._last_lang or "en"
        lang = max(filt, key=filt.get)
        if not force and self._last_lang and lang != self._last_lang:
            if filt.get(lang, 0.0) < 0.50:
                return self._last_lang
        return lang

    def _asr(self, audio: np.ndarray, lang: str) -> str:
        res = self.model.transcribe(  # type: ignore[union-attr]
            audio,
            language=lang,
            task="transcribe",
            fp16=False,
            temperature=0.0,
            best_of=5,
            beam_size=5,
            condition_on_previous_text=False,
            no_speech_threshold=0.3,
        )
        return (res.get("text") or "").strip()

    def _resample_if_needed(self, x: np.ndarray, sr: int) -> np.ndarray:
        if sr == self.sr:
            return x.astype(np.float32)
        ratio = self.sr / float(sr)
        n = int(len(x) * ratio)
        idx = (np.arange(n) / ratio).astype(np.float32)
        idx = np.clip(idx, 0, len(x) - 1)
        return x[idx.astype(np.int32)].astype(np.float32)

    # --- emitters ---
    def _emit_text(self, s: str):
        try: self.on_text(s)
        except Exception: pass

    def _emit_info(self, s: str):
        try: self.on_info(s)
        except Exception: pass

    def _emit_status(self, s: str):
        try: self.on_status(s)
        except Exception: pass
